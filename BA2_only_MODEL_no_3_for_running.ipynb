{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f331e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c4757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SOME KEY PARAMETERS FOR SAMPLING RATES #########\n",
    "AMOUNT_TRAINING = 89\n",
    "AMOUNT_TEST = 38\n",
    "RANDOM_SEED = 5\n",
    "DOUBLE_TRAINING = AMOUNT_TRAINING * 2\n",
    "DOUBLE_TEST = AMOUNT_TEST * 2\n",
    "\n",
    "# 1 for 10 samples, 2 for 20 samples, 3 for 30 samples ...\n",
    "SAMPLING_RATE = 4\n",
    "SAMPLING_REPRESENTATION = SAMPLING_RATE * 10\n",
    "VALIDATION_VALUES_PARAMETER = 0.8\n",
    "\n",
    "\n",
    "###### IMAGE SIZE in pixels ##################\n",
    "IMAGE_HEIGHT = 63;\n",
    "IMAGE_WIDTH = 63;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01da435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name_incorrect</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     video_name\n",
       "labels                         \n",
       "0                           127\n",
       "1                           127\n",
       "file_name_incorrect           3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading video names in a column and labels:\n",
    "os.getcwd()\n",
    "path = '/home/alehof/Sit_to_stand'\n",
    "\n",
    "videos = os.listdir(path)\n",
    "\n",
    "label = []\n",
    "for i in videos:\n",
    "    if \"incorr\" in i:\n",
    "        label.append(0)\n",
    "    elif \"corr\" in i:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(\"file_name_incorrect\")\n",
    "\n",
    "videos = pd.DataFrame(videos, label).reset_index()\n",
    "videos.columns = [\"labels\", \"video_name\"]\n",
    "\n",
    "videos.groupby('labels').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e1183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        video_name\n",
      "labels            \n",
      "0               89\n",
      "1               89\n",
      "        video_name\n",
      "labels            \n",
      "0               38\n",
      "1               38\n"
     ]
    }
   ],
   "source": [
    "# Splitting the videos into Train and Test Videos:\n",
    "incorrect=videos.loc[videos[\"labels\"]==0,]\n",
    "correct=videos.loc[videos[\"labels\"]==1,]\n",
    "\n",
    "incorrect_range=np.arange(len(incorrect))\n",
    "correct_range=np.arange(len(correct))\n",
    "np.random.seed(RANDOM_SEED)\n",
    "np.random.shuffle(incorrect_range)\n",
    "np.random.shuffle(correct_range)\n",
    "\n",
    "correct=correct.iloc[correct_range,]\n",
    "incorrect=incorrect.iloc[incorrect_range,]\n",
    "\n",
    "train_correct=correct.iloc[:AMOUNT_TRAINING,]\n",
    "train_incorrect=incorrect.iloc[:AMOUNT_TRAINING,]\n",
    "test_correct=correct.iloc[AMOUNT_TRAINING:,]\n",
    "test_incorrect=incorrect.iloc[AMOUNT_TRAINING:,]\n",
    "\n",
    "train_set=train_correct.append(train_incorrect)\n",
    "test_set=test_correct.append(test_incorrect)\n",
    "\n",
    "train_set=train_set.reset_index().drop(\"index\",axis=1)\n",
    "test_set=test_set.reset_index().drop(\"index\",axis=1)\n",
    "\n",
    "print(train_set.groupby('labels').count())\n",
    "print(test_set.groupby('labels').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fed37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Already Created\n",
      "Folder Already Created\n",
      "Folder Already Created\n"
     ]
    }
   ],
   "source": [
    "exercises_dir_path = path\n",
    "train_videos_dir = os.path.join(path, \"Train_Videos\")\n",
    "test_videos_dir = os.path.join(path, \"Test_Videos\")\n",
    "try:\n",
    "    os.mkdir(exercises_dir_path)\n",
    "except FileExistsError as ae:\n",
    "    print(\"Folder Already Created\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(train_videos_dir)\n",
    "except FileExistsError as ae:\n",
    "    print(\"Folder Already Created\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(test_videos_dir)\n",
    "except FileExistsError as ae:\n",
    "    print(\"Folder Already Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543d8a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "All frames written in the: Train_Videos Folder\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n",
      "File Already Created\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b398a02d2487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mvideo_capturing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train_Videos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mvideo_capturing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test_Videos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-b398a02d2487>\u001b[0m in \u001b[0;36mvideo_capturing_function\u001b[0;34m(dataset, folder_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mframe_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_write_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_grey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All frames written in the: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Folder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def video_capturing_function(dataset, folder_name):\n",
    "    for i in np.arange(len(dataset)):\n",
    "        video_name = dataset.video_name[i]\n",
    "        video_read_path = os.path.join(path, video_name)\n",
    "        cap = cv2.VideoCapture(video_read_path)\n",
    "        try:\n",
    "            os.mkdir(os.path.join(os.path.join(path, folder_name),\n",
    "                                  video_name.split(\".\")[0]))\n",
    "        except:\n",
    "            print(\"File Already Created\")\n",
    "\n",
    "        train_write_file = os.path.join(os.path.join(path, folder_name),\n",
    "                                        video_name.split(\".\")[0])\n",
    "        cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "        frameRate = cap.get(5)\n",
    "        x = 1\n",
    "        count = 0\n",
    "        while (cap.isOpened()):\n",
    "            frameId = cap.get(1)  # current frame number\n",
    "            ret, frame = cap.read()\n",
    "            if (ret != True):\n",
    "                break\n",
    "            # print(frameRate / 6)\n",
    "            if (frameId % math.floor(frameRate / SAMPLING_RATE) == 0):\n",
    "                # if (frameId % math.floor(frameRate) == 0):\n",
    "                filename = \"frame%d.jpg\" % count;\n",
    "                count += 1\n",
    "                frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                cv2.imwrite(os.path.join(train_write_file, filename), frame_grey)\n",
    "        cap.release()\n",
    "    return print(\"All frames written in the: \" + folder_name + \" Folder\")\n",
    "\n",
    "\n",
    "video_capturing_function(train_set, \"Train_Videos\")\n",
    "video_capturing_function(test_set, \"Test_Videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently not in use\n",
    "# Code to see how many frames are captured for each video:\n",
    "train_dir_path='/home/alehof/Sit_to_stand/Train_Videos'\n",
    "test_dir_path='/home/alehof/Sit_to_stand/Test_Videos'\n",
    "\n",
    "vid_file_name=train_set.video_name[0].split('.')[0]\n",
    "\n",
    "train_frames=[]\n",
    "for i in np.arange(len(train_set.video_name)):\n",
    "    vid_file_name=train_set.video_name[i].split('.')[0]\n",
    "    train_frames.append(len(os.listdir(os.path.join(train_dir_path,vid_file_name))))\n",
    "\n",
    "test_frames=[]\n",
    "for i in np.arange(len(test_set.video_name)):\n",
    "    vid_file_name=test_set.video_name[i].split('.')[0]\n",
    "    test_frames.append(len(os.listdir(os.path.join(test_dir_path,vid_file_name))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf132bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_generating_function(dataset, dir_path):\n",
    "    for i in np.arange(len(dataset.video_name)):\n",
    "        vid_namu = dataset.video_name[i]\n",
    "        vid_path = os.path.join(dir_path, vid_namu.split(\".\")[0])\n",
    "        # print(vid_path)\n",
    "        len_frame = len(os.listdir(vid_path))\n",
    "        # print(len_frame)\n",
    "        # this is an important value (10 i want to utilize 10 frames, maybe i should set this to a constant)\n",
    "        j = SAMPLING_REPRESENTATION - len(os.listdir(vid_path))\n",
    "        # print(j)\n",
    "\n",
    "        if j > 0:\n",
    "            list_frames = os.listdir(vid_path)\n",
    "            print(list_frames)\n",
    "            c = 0\n",
    "            for k in np.arange(j):\n",
    "                list_frames = os.listdir(vid_path)\n",
    "                print(list_frames)\n",
    "                # print(list_frames)\n",
    "                frame = os.path.join(vid_path, list_frames[0])\n",
    "                # print(frame)\n",
    "                # get the first frame to be coppied\n",
    "                # print(frame)\n",
    "                countu = k + len_frame\n",
    "                new_frame = \"frame%d.jpg\" % countu\n",
    "                shutil.copy2(frame, os.path.join(vid_path, new_frame))\n",
    "                # c+=1\n",
    "                # omitting this, I intend to only copy the last frame the amount of times i need it and place it at the end.\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    return print(\"Frame Generation Done!\")\n",
    "\n",
    "\n",
    "frame_generating_function(train_set, train_dir_path)\n",
    "frame_generating_function(test_set, test_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some troubles detected, folder incorrect respectively correct is created but no files placed, that is why error index out of range occurs,\n",
    "# can be overcome if another exercise is copied in the respective folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab854f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation Splitting:\n",
    "label_1_dat=train_set.loc[train_set[\"labels\"]==1,]\n",
    "label_0_dat=train_set.loc[train_set[\"labels\"]==0,]\n",
    "\n",
    "train_len_label1=math.floor(len(label_1_dat)*VALIDATION_VALUES_PARAMETER)\n",
    "train_len_label0=math.floor(len(label_0_dat)*VALIDATION_VALUES_PARAMETER)\n",
    "\n",
    "train_dat_label1=label_1_dat.iloc[:train_len_label1,]\n",
    "train_dat_label0=label_0_dat.iloc[:train_len_label0,]\n",
    "\n",
    "validation_dat_label1=label_1_dat.iloc[train_len_label1:,]\n",
    "validation_dat_label0=label_0_dat.iloc[train_len_label0:,]\n",
    "\n",
    "train_vid_dat=train_dat_label1.append(train_dat_label0,ignore_index=True)\n",
    "validation_vid_dat=validation_dat_label1.append(validation_dat_label0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load function for 10 frames:\n",
    "\n",
    "def data_load_function_SAMPLING_REPRESENTATION_frames(dataset,directory):\n",
    "    frames=[]\n",
    "    for i in np.arange(len(dataset)):\n",
    "        vid_name=dataset.video_name[i].split(\".\")[0]\n",
    "        vid_dir_path=os.path.join(directory,vid_name)\n",
    "        frames_to_select=[]\n",
    "        for l in np.arange(0,SAMPLING_REPRESENTATION):\n",
    "            frames_to_select.append('frame%d.jpg' % l)\n",
    "        vid_data=[]\n",
    "        for frame in frames_to_select:\n",
    "            image=Image.open(os.path.join(vid_dir_path,frame))\n",
    "            image=image.resize((IMAGE_HEIGHT, IMAGE_WIDTH), Image.ANTIALIAS)\n",
    "            datu=np.asarray(image)\n",
    "            normu_dat=datu/255\n",
    "            vid_data.append(normu_dat)\n",
    "        vid_data=np.array(vid_data)\n",
    "        frames.append(vid_data)\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e85fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames train,validation and test data:\n",
    "\n",
    "test_dataset_new=data_load_function_SAMPLING_REPRESENTATION_frames(test_set, test_dir_path)\n",
    "train_dataset_new=data_load_function_SAMPLING_REPRESENTATION_frames(train_vid_dat, train_dir_path)\n",
    "validation_dataset_new= data_load_function_SAMPLING_REPRESENTATION_frames(validation_vid_dat, train_dir_path)\n",
    "\n",
    "test_labels=np.array(test_set.labels)\n",
    "train_labels=np.array(train_vid_dat.labels)\n",
    "validation_labels=np.array(validation_vid_dat.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa215c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTEGER_RESULT =  math.floor(DOUBLE_TRAINING*VALIDATION_VALUES_PARAMETER)\n",
    "INTEGER_RESULT_2 = math.ceil((DOUBLE_TRAINING*(1 - VALIDATION_VALUES_PARAMETER)))\n",
    "# Reshaping tensors to confirm with the model we are going to train:\n",
    "test_dataset_new=test_dataset_new.reshape((DOUBLE_TEST,SAMPLING_REPRESENTATION,IMAGE_HEIGHT,IMAGE_WIDTH,1))\n",
    "train_dataset_new=train_dataset_new.reshape((INTEGER_RESULT,SAMPLING_REPRESENTATION,IMAGE_HEIGHT,IMAGE_WIDTH,1))\n",
    "validation_dataset_new=validation_dataset_new.reshape((INTEGER_RESULT_2,SAMPLING_REPRESENTATION,IMAGE_HEIGHT,IMAGE_WIDTH,1))\n",
    "print(train_dataset_new)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## important to consider exercise numbers, as above 80 % of training will stay training data\n",
    "## 20 % will become validation data \n",
    "## therefore considering the 140 videos i had\n",
    "## i had 98 in training data folder. and 42 in test data folder\n",
    "## 98 * 0,2 = 20 rounded, + 98*0,8 = 78 rounded (math floor), now it matches up.\n",
    "\n",
    "## new try with 80% - 20 %\n",
    "\n",
    "# 110 and 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predictions=np.ones(len(test_labels))\n",
    "test_accuracy_naive=np.where(baseline_predictions==test_labels)[0].shape[0]/len(test_labels)\n",
    "test_accuracy_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9db9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now standard simple CNN and LSTM basic architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df08f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad325d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### REASSIGNING TYPE CONVERSION NEEDED FOR ALL MODELS\n",
    "train_dataset_new=np.asarray(train_dataset_new).astype(np.float32)\n",
    "train_labels=np.asarray(train_labels).astype(np.float32)\n",
    "validation_dataset_new=np.asarray(validation_dataset_new).astype(np.float32)\n",
    "validation_labels=np.asarray(validation_labels).astype(np.float32)\n",
    "test_dataset_new=np.asarray(test_dataset_new).astype(np.float32)\n",
    "test_labels=np.asarray(test_labels).astype(np.float32)\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d05524",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 3D CNN Architecture:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv3D, MaxPooling3D, BatchNormalization, Dropout, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "# 3D Convolutional Model:\n",
    "input_model=Input(shape=(SAMPLING_REPRESENTATION, IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n",
    "layer=Conv3D(32,(3,3,3),strides=(1,1,1),activation='relu')(input_model)\n",
    "layer=MaxPooling3D((2,2,2))(layer)\n",
    "layer=Conv3D(64,(3,3,3),strides=(1,1,1),activation='relu')(layer)\n",
    "layer=MaxPooling3D((2,2,2))(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=Flatten()(layer)\n",
    "layer=Dense(128,activation='relu')(layer)\n",
    "layer=Dropout(0.1)(layer)\n",
    "layer=Dense(64,activation='relu')(layer)\n",
    "layer=Dense(32,activation='relu')(layer)\n",
    "layer_output=Dense(1,activation='sigmoid')(layer)\n",
    "\n",
    "model_3dConv=Model(input_model,layer_output)\n",
    "\n",
    "model_3dConv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODEL _ KEYPARAMETERS\n",
    "\n",
    "FACTOR = 0.1\n",
    "PATIENCE = 4\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 14\n",
    "\n",
    "##### USING TIME TO STORE MODEL NAME\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "\n",
    "FILEPATH = 'cnn_lstm_model_3_' + timestr + '.h5'\n",
    "print(FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f988811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv3d model training:\n",
    "from keras import optimizers\n",
    "optimizer_new=optimizers.RMSprop(lr=0.1)\n",
    "optimizer_adagrad=keras.optimizers.Adagrad(lr=0.01)\n",
    "callbacks_list_conv_3d=[keras.callbacks.EarlyStopping(\n",
    "monitor='acc',patience=4),\n",
    "               keras.callbacks.ModelCheckpoint(\n",
    "               filepath=FILEPATH,\n",
    "               monitor='val_loss',\n",
    "               save_best_only=True),\n",
    "                        keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = FACTOR, patience = PATIENCE)\n",
    "               ]\n",
    "model_3dConv.compile(optimizer=optimizer_adagrad,loss='binary_crossentropy',metrics=['acc'])\n",
    "conv_3d_model_history=model_3dConv.fit(train_dataset_new,train_labels,batch_size=BATCH_SIZE,epochs=EPOCHS,\n",
    "               validation_data=(validation_dataset_new,validation_labels),\n",
    "               callbacks=callbacks_list_conv_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93b65d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=conv_3d_model_history.history[\"acc\"]\n",
    "val_acc=conv_3d_model_history.history[\"val_acc\"]\n",
    "loss=conv_3d_model_history.history[\"loss\"]\n",
    "val_loss=conv_3d_model_history.history[\"val_loss\"]\n",
    "\n",
    "\n",
    "epochs=np.arange(1,14)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(epochs,val_acc,'-o')\n",
    "plt.title('Validation Accuracy')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(epochs,acc,'-o')\n",
    "plt.title('Train Accuracy')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(epochs,val_loss,'-o')\n",
    "plt.title('Validation Loss')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(epochs,loss,'-o')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b409d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 512ms/step - loss: 0.0652 - acc: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0651533454656601, 0.9868420958518982]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelu_6=load_model('stretch_model_conv_3d_new4.h5')\n",
    "modelu_6=load_model(FILEPATH)\n",
    "modelu_6.evaluate(test_dataset_new,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ed2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the two best models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42e6b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelu_cnlst_1=load_model('cnn_lstm_model_3_20210620-090949.h5')\n",
    "### FOR TIMES SAKE 2 times the same\n",
    "modelu_cnlst_2=load_model('cnn_lstm_model_3_20210620-090949.h5')\n",
    "\n",
    "# since they were already loaded -> the model names need to be manually asigned here \n",
    "#modelu_cnlst_1=load_model('cnn_lstm_model_new3.h5')\n",
    "#modelu_cnlst_2=load_model('cnn_lstm_model_new4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "261f63e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vid_3.mp4', 'vid_5.mp4', 'test_rl_1.mp4', 'vid_2.mp4', 'vid_1.mp4', 'vid_7.mp4', 'vid_8.mp4', 'vid_0.mp4', 'vid_9.mp4', 'vid_4.mp4', 'test_rl_1', 'vid_6.mp4']\n"
     ]
    }
   ],
   "source": [
    "#Video Folder Create Function:¶\n",
    "video_list=os.listdir(os.path.join(path,'test_rl_1'))\n",
    "\n",
    "print(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b37c0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alehof/Sit_to_stand\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aed420fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in ./BA2/lib/python3.8/site-packages (1.0.3)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5; python_version >= \"3.4\" in ./BA2/lib/python3.8/site-packages (from moviepy) (2.9.0)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in ./BA2/lib/python3.8/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0; python_version >= \"3.4\" in ./BA2/lib/python3.8/site-packages (from moviepy) (0.4.4)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version != \"2.7\" in ./BA2/lib/python3.8/site-packages (from moviepy) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in ./BA2/lib/python3.8/site-packages (from moviepy) (2.22.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in ./BA2/lib/python3.8/site-packages (from moviepy) (0.1.9)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in ./BA2/lib/python3.8/site-packages (from moviepy) (4.61.2)\n",
      "Requirement already satisfied: pillow in ./BA2/lib/python3.8/site-packages (from imageio<3.0,>=2.5; python_version >= \"3.4\"->moviepy) (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "545dc004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already created\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_0.mp4.\n",
      "MoviePy - Writing audio in vid_0TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_0.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_1.mp4.\n",
      "MoviePy - Writing audio in vid_1TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_1.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_2.mp4.\n",
      "MoviePy - Writing audio in vid_2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_2.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_3.mp4.\n",
      "MoviePy - Writing audio in vid_3TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_3.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_4.mp4.\n",
      "MoviePy - Writing audio in vid_4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_4.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_5.mp4.\n",
      "MoviePy - Writing audio in vid_5TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_5.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_6.mp4.\n",
      "MoviePy - Writing audio in vid_6TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_6.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_6.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_7.mp4.\n",
      "MoviePy - Writing audio in vid_7TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_7.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_7.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_8.mp4.\n",
      "MoviePy - Writing audio in vid_8TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_8.mp4\n",
      "Moviepy - Building video /home/alehof/Sit_to_stand/test_rl_1/vid_9.mp4.\n",
      "MoviePy - Writing audio in vid_9TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/alehof/Sit_to_stand/test_rl_1/vid_9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/alehof/Sit_to_stand/test_rl_1/vid_9.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "def video_folder_create(path,video_folder_name,video_name):\n",
    "    video_folder_path=os.path.join(path,video_folder_name)\n",
    "    try:\n",
    "        os.mkdir(os.path.join(video_folder_path,video_folder_name))\n",
    "    except:\n",
    "        print(\"Folder already created\")\n",
    "    input_video_path=os.path.join(path,video_name)\n",
    "    times=[[0,5],[6,10],[11,15],[16,20],[21,25],[26,30],[31,35],[36,40],[41,45],[46,50]]\n",
    "    for i in np.arange(len(times)):\n",
    "        vid_name=\"vid_%d.mp4\" % i\n",
    "        output_video_path=os.path.join(video_folder_path,vid_name)\n",
    "        with VideoFileClip(input_video_path) as video:\n",
    "            new = video.subclip(times[i][0], times[i][1])\n",
    "            new.write_videofile(output_video_path,audio_codec='aac')\n",
    "    return True\n",
    "\n",
    "# Creating 5 folders for 5 test videos:\n",
    "video_folder_create(path,'test_rl_1','test_rl_1.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "567e052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_prediction(path,video_folder_name):\n",
    "    folder_path=os.path.join(path,video_folder_name)\n",
    "    video_list=os.listdir(folder_path)\n",
    "    prediction_list_1=[]\n",
    "    prediction_list_2=[]\n",
    "    for i in np.arange(len(video_list)):\n",
    "        video_path=os.path.join(folder_path,video_list[i])\n",
    "        cap=cv2.VideoCapture(video_path)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 1)\n",
    "        frameRate=cap.get(5)\n",
    "        x=1\n",
    "        count=0\n",
    "        frame_saved=[]\n",
    "        while(cap.isOpened()):\n",
    "            frameId = cap.get(1) #current frame number\n",
    "            ret, frame = cap.read()\n",
    "            if (ret != True):\n",
    "                break\n",
    "            if (frameId % math.floor(frameRate) == 0):\n",
    "                frame_grey=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frame_grey=cv2.resize(frame_grey,(63,63))\n",
    "                frame_grey=frame_grey/255\n",
    "                frame_saved.append(frame_grey)\n",
    "        cap.release()\n",
    "        frame_diff=10-len(frame_saved)\n",
    "        if frame_diff>0:\n",
    "            for k in np.arange(frame_diff):\n",
    "                frame_saved.append(frame_saved[k])\n",
    "        else:\n",
    "            pass\n",
    "        frame_saved=frame_saved[:10]\n",
    "        frame_saved=np.array(frame_saved)\n",
    "        dats=frame_saved.reshape((1,10,63,63,1))\n",
    "        prediction_list_1.append(modelu_cnlst_1.predict(dats))\n",
    "    return prediction_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b900816",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/training.py:1544 predict_function  *\n        return step_function(self, iterator)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/training.py:1527 run_step  *\n        outputs = model.predict_step(data)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/training.py:1500 predict_step  *\n        return self(x, training=False)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/input_spec.py:264 assert_input_compatibility  *\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 20, 63, 63, 1), found shape=(None, 10, None, None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c1704dca1ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction_model_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_time_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test_rl_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_model_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredu_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction_model_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredu_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-fdd3d8ae4c4b>\u001b[0m in \u001b[0;36mreal_time_prediction\u001b[0;34m(path, video_folder_name)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mframe_saved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_saved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe_saved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mprediction_list_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelu_cnlst_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_list_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprediction_list_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelu_cnlst_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1700\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m-> 3022\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3440\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3441\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3360\u001b[0m           expand_composites=True)\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3362\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3363\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BA2_action_recogntion/BA2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/training.py:1544 predict_function  *\n        return step_function(self, iterator)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/training.py:1527 run_step  *\n        outputs = model.predict_step(data)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/training.py:1500 predict_step  *\n        return self(x, training=False)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/alehof/BA2_action_recogntion/BA2/lib/python3.8/site-packages/keras/engine/input_spec.py:264 assert_input_compatibility  *\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 20, 63, 63, 1), found shape=(None, 10, None, None, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction_model_1=real_time_prediction(path,\"test_rl_1\")\n",
    "\n",
    "predu_1=[]\n",
    "for i in prediction_model_1:\n",
    "    predu_1.append(list(i[0])[0])\n",
    "#predu_2=[]\n",
    "#for i in prediction_model_2:\n",
    "#    predu_2.append(list(i[0])[0])\n",
    "times=[[0,5],[6,10],[11,15],[16,20],[21,25],[26,30],[31,35],[36,40],[41,45],[46,50]]\n",
    "time_axis=[]\n",
    "for i in times:\n",
    "    time_axis.append(str(i[0])+\"_\"+str(i[1]))\n",
    "    \n",
    "# main_preds=np.average(np.array([predu_1,predu_2]),axis=0)\n",
    "main_preds=np.array(predu_1)\n",
    "print(main_preds)\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(time_axis,main_preds,\"-o\")\n",
    "plt.xlabel(\"Time slots of video in Seconds\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(\"Model_Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe160d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
